{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de728144-b96a-442a-b48b-23c44c7d6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluatormodel.py\n",
    "\"\"\"\n",
    "Evaluator pipeline:\n",
    "1) Run a target chatbot (Study Buddy) with system prompt from your session.\n",
    "2) Capture its output to a user query.\n",
    "3) Run an Evaluator model (separate LLM instance) with the rubric prompt to score\n",
    "   the target model's output and return JSON-like scores + feedback.\n",
    "\n",
    "Requirements:\n",
    "    pip install google\n",
    "Usage:\n",
    "    export GOOGLE_API_KEY=\"your_key_here\"    # Linux / macOS\n",
    "    python evaluatormodel.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "\n",
    "# ------------- Configure API Key -------------\n",
    "# Option 1: set environment variable outside this file:\n",
    "#    export GOOGLE_API_KEY=\"YOUR_API_KEY\"\n",
    "# Option 2: for quick tests only (not recommended for production), uncomment:\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"xxxx\"\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    raise ValueError(\"Please set the GOOGLE_API_KEY environment variable.\")\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935b4b48-fef7-4acd-a860-0aca58fd3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_examples = pd.read_csv(\"dataset.csv\")\n",
    "df_examples.head(2)\n",
    "\n",
    "# Assume your Excel has columns: \"message\" and \"label\"\n",
    "examples = []\n",
    "for _, row in df_examples.iterrows():\n",
    "    msg = row['message_text']\n",
    "    lbl = row['label']  # 'Scam', 'Not Scam', or 'Uncertain'\n",
    "    reasoning = row.get('reasoning', f\"Classified as {lbl}\")  # optional column\n",
    "    intent = row.get('intent_type', \"Unknown\")  # optional column\n",
    "    risk_factors = row.get('flag_reason', \"[]\")  # optional column\n",
    "\n",
    "    # Format as JSON string\n",
    "    example_json = f\"\"\"{{\n",
    "  \"label\": \"{lbl}\",\n",
    "  \"reasoning\": \"{reasoning}\",\n",
    "  \"intent\": \"{intent}\",\n",
    "  \"risk_factors\": {risk_factors}\n",
    "}}\"\"\"\n",
    "\n",
    "    examples.append(f'Input message: \"{msg}\"\\nResponse:\\n{example_json}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0405326-573d-45e8-ac92-cfb37998f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scam Guard AI - Type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- SYSTEM PROMPT ---\n",
    "SCAM_GUARD_SYSTEM_PROMPT = \"\"\"\n",
    "You are \"Scam Guard\" ‚Äî a smart AI that helps users identify potential scams in messages. \n",
    "Analyze each message carefully and provide structured JSON output with reasoning.\n",
    "\n",
    "Rules:\n",
    "1. RESPONSE FORMAT (STRICT JSON):\n",
    "{{\n",
    "  \"label\": \"Scam\" | \"Not Scam\" | \"Uncertain\",\n",
    "  \"reasoning\": \"Step-by-step reasoning why the message is suspicious or safe\",\n",
    "  \"intent\": \"Purpose of the message\",\n",
    "  \"risk_factors\": [\"list\", \"of\", \"red flags\"]\n",
    "}}\n",
    "\n",
    "2. TONE:\n",
    "- Friendly but cautionary\n",
    "- Informative, do not over-alarm\n",
    "\n",
    "3. EXAMPLES:\n",
    "\"\"\" + \"\\n\\n\".join(examples)\n",
    "\n",
    "# Initialize single Gemini 2.5 model\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    system_instruction=SCAM_GUARD_SYSTEM_PROMPT\n",
    ")\n",
    "\n",
    "chat = model.start_chat()\n",
    "\n",
    "\n",
    "def safe_parse_json(text: str):\n",
    "    \"\"\"Extract first JSON object-looking substring and parse.\"\"\"\n",
    "    stack = []\n",
    "    start = None\n",
    "    for i, ch in enumerate(text):\n",
    "        if ch == '{':\n",
    "            if start is None:\n",
    "                start = i\n",
    "            stack.append('{')\n",
    "        elif ch == '}':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack and start is not None:\n",
    "                    candidate = text[start:i+1]\n",
    "                    try:\n",
    "                        return json.loads(candidate)\n",
    "                    except Exception:\n",
    "                        candidate_fixed = candidate.replace(\"'\", \"\\\"\")\n",
    "                        candidate_fixed = re.sub(r\",\\s*}\", \"}\", candidate_fixed)\n",
    "                        candidate_fixed = re.sub(r\",\\s*]\", \"]\", candidate_fixed)\n",
    "                        try:\n",
    "                            return json.loads(candidate_fixed)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    start = None\n",
    "    raise ValueError(\"No valid JSON object found in model output.\")\n",
    "\n",
    "\n",
    "def detect_scam(message: str):\n",
    "    \"\"\"Send message to Scam Guard AI and return JSON output.\"\"\"\n",
    "    raw_output = chat.send_message(message).text\n",
    "    try:\n",
    "        return safe_parse_json(raw_output)\n",
    "    except Exception:\n",
    "        # fallback if JSON parsing fails\n",
    "        return {\n",
    "            \"label\": \"Uncertain\",\n",
    "            \"reasoning\": \"Failed to parse model output as JSON.\",\n",
    "            \"intent\": \"Unknown\",\n",
    "            \"risk_factors\": []\n",
    "        }\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Scam Guard AI - Type 'exit' to quit.\\n\")\n",
    "    while True:\n",
    "        msg = input(\"Enter message: \").strip()\n",
    "        if msg.lower() == \"exit\":\n",
    "            print(\"Goodbye! Stay safe online. üõ°Ô∏è\")\n",
    "            break\n",
    "        if not msg:\n",
    "            continue\n",
    "\n",
    "        result = detect_scam(msg)\n",
    "        print(\"\\n=== Detection Result ===\")\n",
    "        print(json.dumps(result, indent=2))\n",
    "        print(\"=======================\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91e6b5-d896-4f05-bb62-772ed01f466a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb1973-4675-4658-8fb1-a42c29d7f66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-genai]",
   "language": "python",
   "name": "conda-env-anaconda3-genai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
